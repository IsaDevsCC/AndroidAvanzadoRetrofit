{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice in Wonderland\n",
    "\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](lewis_carroll.jpg)\n",
    "\n",
    "El matemático *Charles Dodgson*, más conocido por el pseudónimo con el que escribió libros infantiles, *Lewis Carroll*. Tanto su obsesión por las matemáticas y la lógica, como su caracter introvertido (se cree que padecía de autismo) se vislumbran en su obra \"infantil\". \n",
    "\n",
    "Era lo que hoy llamaríamos un *friki* y un *nerd*, razones más que suficientes para explicar la popularidad de sus libros entre lso programadores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto de prueba\n",
    "\n",
    "Usaremos el texto completo de *Alice in Wonderland* para comprobar el funcionamiento de nuestro software, aunque serviría cualquier fichero de texto.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "También usaremos un documento de texto que contiene las *stopwords* más comunes en Inglés. \n",
    "\n",
    "Las \"stopwords\" en el Procesamiento del Lenguaje Natural (NLP, por sus siglas en inglés) se refieren a las palabras más comunes en un idioma que generalmente se filtran o se eliminan antes o después del procesamiento de texto. La razón de esto es que estas palabras no aportan mucha información útil para entender el significado de una oración. Suelen ser palabras funcionales como \"el\", \"la\", \"y\", \"de\", etc.\n",
    "\n",
    "Una lista de \"stopwords\" puede variar dependiendo del contexto o de la tarea en cuestión, pero generalmente se conforma de las palabras más comunes en el idioma."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ficheros disponibles\n",
    "\n",
    "1. `alice_full_text.txt`  Texto completo, sacado del Proyecto Gutemberg.\n",
    "2. `stopwords.txt` lista de stopwords comunes en Inglés\n",
    "\n",
    "Recuerda que para que sea útil, las stopwords tienen que ser las del lenguaje que vamos a analizar.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas\n",
    "\n",
    "El objetivo final es crear la siguiente función:\n",
    "\n",
    "`count_words(tokens: list[str], stopwords: set[str]) -> dict[str:int]`\n",
    "\n",
    "1. Recibe una lista con los tokens (palabras) asi como un `set[str]` con las *stopwords*.\n",
    "2. Devuelve un `dict[str:int]` con las palabras únicas y sus correspondientes probabilidades.\n",
    "3. Como un extra, deberemos averiguar cómo mejor presentar ese diccionario final al usuario.\n",
    "4. Para comprobar el funcionamineto, usaremos los dos ficheros de texto que nos han proporcionado.\n",
    "\n",
    "> Es demasié pal body, así que vamos a romperlo en subtareas que sean más llevaderas.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Tareas (*Divide & Vencerás*)\n",
    "\n",
    "`count_words` se rompe en las siguientes tareas:\n",
    "\n",
    "\n",
    "1. Contar las ocurrencias de cada palabra, ignorando las stopwords y guardando los datos en un `dict[str:int]`.\n",
    "2. Transformar ese número de ocurrencias en una probabilidad (para lo cual necesitaremos el número total de palabras). El resultado final será un `dict[str:float]`.\n",
    "   \n",
    "Además, `count_words` tiene dos precondiciones:\n",
    "\n",
    "1. Tokenizar el texto.\n",
    "2. Crear el `set` de stopwords.\n",
    "\n",
    "Ambas son tareas que podemos subdividir en:\n",
    "\n",
    "1. Leer el fichero correspondiente.\n",
    "2. Tokenizar \n",
    "3. Limpiar de *guarreridas* si las hay\n",
    "4. Normalizar la representación\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `count_words`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carta a los Reyes Magos\n",
    "\n",
    "Empezamos por la función principal (¡Caña al mono hasta que pase los tests!) y lo haremos con la *cartita a los Reyes Magos* describiendo qué sería lo ideal. Una vez tengamos eso claro (el objetivo), empezamos a trabajar por él.\n",
    "\n",
    "\n",
    "Crea un fichero llamado `histogram.py` y en él vamos a crear la función `count_words`. \n",
    "\n",
    "Antes de seguir, vamos a definir algunos tipos que representan las principales estructuras de datos que vamos a usar:\n",
    "\n",
    "```Python\n",
    " Types\n",
    "Histogram = dict[str:float]\n",
    "Totals = dict[str:int]\n",
    "Word = str\n",
    "Words = list[Word]\n",
    "Stopwords = set[Word]\n",
    "```\n",
    "Con esto, podemos definir nuestra función de manera más clara:\n",
    "\n",
    "```Python\n",
    "def count_words(text_words: words, stop_words: stopwords) -> totals:\n",
    "    # creamos un `totals` vacío que iremos actualizando\n",
    "    # si una palabra de text_words ya está en el totals, incrementamos en 1\n",
    "    # su valor.\n",
    "    # si no lo está, y tampoco está en las stopwords, asignamos un\n",
    "    # valor de 1\n",
    "    # devolvemos el totals\n",
    "    pass\n",
    "```\n",
    "\n",
    "1. Implementa esta función en el fichero `histogram`\n",
    "2. Importa esa función (y los tipos que usa) al Notebook\n",
    "3. Comprueba su funcionamiento con algunos datos pequeños.\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener un gran total de palabras\n",
    "\n",
    "Ya tenemos un `Totals`, pero necesitamso convertir esos totales en probabilidades. Para ello, necesitamos saber el total de palabras (excluyendo las stopwords).\n",
    "\n",
    "La definición de Probabilidad es:\n",
    "\n",
    "$$Probabilidad = \\frac {Casos Deseables}{Casos Posibles}$$\n",
    "\n",
    "Así que tendremos que dividir el valor de cada total por el total de palabras.\n",
    "\n",
    "Lo primero, por lo tanto, es obtener el gran total de palabras, sumando todas las courrencias de cada una de las palabras.\n",
    "\n",
    "`grand_total_words(word_totals: Totals)->int`\n",
    "\n",
    "Se trata de una función que recibe un diccionario y devuelve un entero. Es decir, es un *compresor*. La única diferencia es que en vez de aceptar una lista de valores, recibe un diccionario.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterable\n",
    "\n",
    "En realidad, un *compresor* **no necesita recibir una lista, sino un `iterable`**.\n",
    "\n",
    "> Un iterable en Python es cualquier objeto capaz de devolver sus elementos uno a la vez, permitiendo que sea recorrido en un bucle.\n",
    "\n",
    "En Python, muchos objetos son iterables. Los más comunes son:\n",
    "\n",
    "1. Las listas: `lista = [1, 2, 3, 4, 5]`\n",
    "2. Los diccionarios: `diccionario = {'uno': 1, 'dos': 2, 'tres': 3}`\n",
    "3. Los conjuntos: `conjunto = {1, 2, 3, 4, 5}`\n",
    "4. Las cadenas de texto: `cadena = \"Hola Mundo\"`\n",
    "5. Otros que aun no hemos visto. Mira la documentación.\n",
    "\n",
    "> Todos ellos se pueden iterar con un bucle `for`\n",
    "\n",
    "Por lo tanto, las definiciones de *compresor*, *selector* y *transformador* se modifican de la siguiente manera:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compresor**: función que recibe un *iterable* de elementos, y lo comprime a un único elemento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selector**: función que recibe un *iterable* y un predicado y devuelve otro iterable con los elementos que pasan el test del predicado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformador**: función que recibe un iterable y una función que actúa sobre cada elemento del iterable. Devuelve otro iterable de la misma longitud, con los elementos transformados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crea un fichero llamado `data_processing.py` y pega el compresor, selector y transformador universales.\n",
    "2. En `histogram`, implementa la función `grand_total_words(word_totals: Totals)->int`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma\n",
    "\n",
    "Ahora ya tenemos los dos ingredientes que nos hacía falta para crear el histograma:\n",
    "\n",
    "* El número total de ocurrencias de todas las palabras\n",
    "* El número de ocurrencias de cada una\n",
    "\n",
    "Ya sólo tenemos que crear un `dict` con las palabras y su probabilidad (total de esa palabra / total de todas). Para ello tenemos la siguiente función:\n",
    "\n",
    "`make_histogram(word_totals: Totals, grand_total: int)->Histogram`\n",
    "\n",
    "Se trata de un ++Trasnformador*, que recib eun iterable y devuelve otro."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementa la función usando el transformador universal.\n",
    "2. Mira de nuevo la función `count_words`. ¿Qué tipo de función es? ¿Se podría re-escribir en base a `compress`?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión: Mono Dominado\n",
    "\n",
    "![](mono.jpg)\n",
    "\n",
    "La parte central de nuestro software (el *mono*) ya está dominada. Sólo nos quedan los pre-requisitos:\n",
    "\n",
    "1. Construir el set de stopwords a partir del contenido del fichero\n",
    "2. Construir la lista de palabras a partir del fichero.\n",
    "\n",
    "Empezaremos por las stopwords, que parece más fácil.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
